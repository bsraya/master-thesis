# Abstract

# Introduction

Deep learning has been one of the sought-after fields in the research community. Due to the deep learning algorithms efficiency in inferring information, a great number of researchers from different fields has been using Deep Learning to help them automating a certain task, such as inference or classification.

Deep Learning is one of the machine learning methods based on neural networks with representational learning. Deep learning can be categorized into five problems: learning problems, hybrid learning problems, statistical, inference, and learning techniques. However, two types of problems are going to be the main highlight, namely learning and hybrid leaning problems. Learning problems include supervised, unsupervised, and reinforcement learning. Hybrid learning problems include semi-supervised, self-supervised, and multi-instance learning.

Even though many deep learning algorithms have been more efficient given the number of research have been done to improve them, their efficiencies are still no match to the size of data that is generated everyday. Thus, a new approach of training models was needed to solve this issue. 

In 2018, two engineers from Uber Technologies made a framework that capable of solving the aforementioned issue. They proposed a method that allows models to be trained parallely with one or more graphic cards.

Even though a model can be trained with multiple graphic cards, users still have to manually consider the amount of resources each model requires. Most of the time, users will over or under estimate the amount of resources needed to train a model. This will result in either wasting resources or not being able to train the model at all. If users do not have to worry about the amount of resources needed to train a model, they can focus more on the model itself.

In this thesis, I will be proposing a system that schedules deep learning models with fixed or dynamic amount resources to an available machine. Most importantly, it enables users to train deep learning models with one or more graphic cards. Users can choose to predetermine  or let the system assesses the amount of graphic cards required to train deep learning models. Moreover, after the resources required is already predetermined or determined, this framework will algorithmically assign the models to available machines in order to maximize resource utilization. Since this framework is made to schedule deep learning models, thus it is called Schedulearn.

# Related Work

# Methodology

# Implementation

# Analysis


# Conclusion